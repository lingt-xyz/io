---
layout: post
title: Notes for SAFE
mathjax: false
comments: false
share: false
tags: [binary, similarity detection, neural network, embedding]
---

Reading Notes for *SAFE: Self-Attentive Function Embeddings for Binary Similarity* by Luca Massarelli, Giuseppe Antonio Di Luna , Fabio Petroni, Roberto Baldoni, and Leonardo Querzoni.

<!--more-->
## Limitations of existing techniques
* Use manually selected features, introducing potential bias.
* Assume call symbols to dynamically linking libraries are available in binary functions, while this is not true for binaries that are stripped and statically linked or in partial binary fragments.
* Usually work only on specific CPU architectures.
 
## Idea
* Transform binary functions into vectors of numbers (embeddings)
* Two phases
    1. Transform a sequence of assembly instructions in a sequence of vectors.
    2. Transform a sequence of vectors in a single embedding vector.

## How
1. Assembly Instructions Embeddings (`i2v`)
    * What: associate an embedding vector to each instruction contained in a function
    * How: train the embedding model `i2v` using the skip-gram method.
        * Using assembly instructions as tokens with filtering.
2. Self-attentive Network
    * RNN: feed a bi-directional recurrent neural network with the sequence of assembly vectors.

## Advantage
1. Does not use debug symbols.
2. Does not need the CFG.
3. Once the embeddings are computed, checking the similarity is relatively cheap and fast.
4. Embeddings can be used as input to other machine learning algorithms.
