---
layout: post
title: Notes for INNEREYE
mathjax: false
comments: false
share: false
tags: [binary, similarity detection, neural network, embedding, Natural Language Processing]
---

Reading Notes for *Neural Machine Translation Inspired Binary Code Similarity Comparison beyond Function Pairs* by Fei Zuo, Xiaopeng Li, Patrick Young, Lannan Luo, Qiang Zeng, Zhexin Zhang.

<!--more-->

## Limitations of existing techniques
* Using several manually selected features causes information loss in terms of the contained instructions and the dependencies between these instructions.

## Problems
1. Problem I: Given a pair of basic blocks of different instruction set architectures (ISAs), determining whether their semantics is similar.
2. Problem II: Given a piece of code of interest, determining if it is contained in another piece of code of a different ISA (code containment problem).

## Idea
* NMT: Neural Machine Translation
* Regard instructions as words and basic blocks as sentences
* Consider the task of detecting whether two basic blocks of different ISAs are semantically similar is analogous to that of dtermining whether two sentences of different human languages have similar meanings.
* So, convert a basic block into an embedding
    * Not only encode basic-block semantics,
    * also capture semantic relationships across architectures.

## Overview
* Code component semantics:
    1. Basic blocks: neural network-based cross-lingual basic-block embedding model to represent a basic block as an embedding
        * Siamese architecutre
    2. CFG paths: LCS
    3. Code components: explore multiple path pairs to collectively calculate a similarity score

## How
1. Instruction embedding generation
    * Dataset
    * OOV: out-of-vocabulary
2. Block embedding generation
    * LSTM in RNN
4. Path/Code componet similarity comparison
    * Decompose the CFG into multiple paths

## Problems
1. Diverse compilers
2. Obfuscations on the basic block level